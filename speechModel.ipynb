{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sean\\AppData\\Local\\Programs\\Python\\Python37\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "# python 3.7 is needed for azure cognitive speech services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from keys import *\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. constant voice recognition\n",
    "2. intermittent translation\n",
    "3. speech model -> transcribe -> tts\n",
    "\n",
    "4. test with video of dysarthric speaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_recognize_continuous_async_from_microphone():\n",
    "    \"\"\"performs continuous speech recognition asynchronously with input from microphone\"\"\"\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=subscription, region=\"westus\")\n",
    "    # The default language is \"en-us\".\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config)\n",
    "\n",
    "    done = False\n",
    "\n",
    "    def recognizing_cb(evt: speechsdk.SpeechRecognitionEventArgs):\n",
    "    \n",
    "        print('RECOGNIZING: {}'.format(evt))\n",
    "\n",
    "    def recognized_cb(evt: speechsdk.SpeechRecognitionEventArgs):\n",
    "        \n",
    "        #print(evt.result.text)\n",
    "        print('RECOGNIZED: {}'.format(evt))\n",
    "\n",
    "    def stop_cb(evt: speechsdk.SessionEventArgs):\n",
    "        \"\"\"callback that signals to stop continuous recognition\"\"\"\n",
    "        print('CLOSING on {}'.format(evt))\n",
    "        nonlocal done\n",
    "        done = True\n",
    "\n",
    "    # Connect callbacks to the events fired by the speech recognizer\n",
    "    speech_recognizer.recognizing.connect(recognizing_cb)\n",
    "    speech_recognizer.recognized.connect(recognized_cb)\n",
    "    speech_recognizer.session_stopped.connect(stop_cb)\n",
    "    speech_recognizer.canceled.connect(stop_cb)\n",
    "\n",
    "    # Perform recognition. `start_continuous_recognition_async asynchronously initiates continuous recognition operation,\n",
    "    # Other tasks can be performed on this thread while recognition starts...\n",
    "    # wait on result_future.get() to know when initialization is done.\n",
    "    # Call stop_continuous_recognition_async() to stop recognition.\n",
    "    result_future = speech_recognizer.start_continuous_recognition_async()\n",
    "\n",
    "    result_future.get()  # wait for voidfuture, so we know engine initialization is done.\n",
    "    print('Continuous Recognition is now running, say something.')\n",
    "\n",
    "    while not done:\n",
    "        # No real sample parallel work to do on this thread, so just wait for user to type stop.\n",
    "        # Can't exit function or speech_recognizer will go out of scope and be destroyed while running.\n",
    "        print('type \"start\" to begin')\n",
    "        stop = input()\n",
    "        if (stop.lower() == \"start\"):\n",
    "            print('Starting async recognition.')\n",
    "            speech_recognizer.stop_continuous_recognition_async()\n",
    "            done = True\n",
    "            break\n",
    "\n",
    "    print(\"Starting async continuous recognition.\")\n",
    "    #speech_recognizer.stop_continuous_recognition_async()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous Recognition is now running, say something.\n",
      "type \"start\" to begin\n",
      "RECOGNIZING: SpeechRecognitionEventArgs(session_id=16cae0dfd9b24a41b346008dad3a59d4, result=SpeechRecognitionResult(result_id=210dd51a3a5740db876bc52cf51ca86d, text=\"is it working\", reason=ResultReason.RecognizingSpeech))\n",
      "RECOGNIZED: SpeechRecognitionEventArgs(session_id=16cae0dfd9b24a41b346008dad3a59d4, result=SpeechRecognitionResult(result_id=d87fd4db80ab4e57a68eef74a58ea3af, text=\"Is it working?\", reason=ResultReason.RecognizedSpeech))\n",
      "Starting async recognition.\n",
      "Starting async continuous recognition.\n"
     ]
    }
   ],
   "source": [
    "speech_recognize_continuous_async_from_microphone()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speak into your microphone.\n",
      "<class 'azure.cognitiveservices.speech.SpeechRecognitionResult'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def from_mic():\n",
    "\n",
    "        speech_config = speechsdk.SpeechConfig(subscription= subscription, region=\"westus\")\n",
    "        speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config)\n",
    "        print(\"Speak into your microphone.\")\n",
    "        result = speech_recognizer.recognize_once_async().get()\n",
    "        print(type(result))\n",
    "        print(result.text)\n",
    "\n",
    "from_mic()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stt():\n",
    "\n",
    "    config = speechsdk.SpeechConfig(subscription=subscription, region=\"westus\")\n",
    "    config.endpoint_id = endpoint\n",
    "\n",
    "    def from_file():\n",
    "        audio = speechsdk.AudioConfig(filename=\"data/my_tip_number_one.wav\")\n",
    "        speech_recognizer = speechsdk.SpeechRecognizer(speech_config=config, audio_config=audio)\n",
    "\n",
    "        result = speech_recognizer.recognize_once_async().get()\n",
    "        print(result.text)\n",
    "\n",
    "    from_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REST API\n",
    "# restLink = \"https://westus3.stt.speech.microsoft.com/speech/recognition/conversation/cognitiveservices/v1?cid=398d0cf9-b231-4521-912f-f208610e48f1\"\n",
    "\n",
    "def tss():\n",
    "    speech_config = speechsdk.SpeechConfig(subscription= subscription, region='westus')\n",
    "    audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\n",
    "\n",
    "    # The language of the voice that speaks.\n",
    "    speech_config.speech_synthesis_voice_name='en-US-JennyNeural'\n",
    "\n",
    "    speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "    # Get text from the console and synthesize to the default speaker.\n",
    "    print(\"Enter some text that you want to speak >\")\n",
    "    text = \"hello my name is\"\n",
    "\n",
    "    speech_synthesis_result = speech_synthesizer.speak_text_async(text).get()\n",
    "\n",
    "    if speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "        print(\"Speech synthesized for text [{}]\".format(text))\n",
    "    elif speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = speech_synthesis_result.cancellation_details\n",
    "        print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n",
    "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            if cancellation_details.error_details:\n",
    "                print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "                print(\"Did you set the speech resource key and region values?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "stt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speak into your microphone.\n",
      "<class 'azure.cognitiveservices.speech.SpeechRecognitionResult'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from_mic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter some text that you want to speak >\n",
      "Speech synthesis canceled: CancellationReason.Error\n",
      "Error details: WebSocket upgrade failed: Authentication error (401). Please check subscription information and region name. USP state: 2. Received audio size: 0 bytes.\n",
      "Did you set the speech resource key and region values?\n"
     ]
    }
   ],
   "source": [
    "tss()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
